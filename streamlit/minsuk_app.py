import mysql.connector as msql
import pandas as pd
import time  # to simulate a real time data, time loop
from streamlit_folium import st_folium
import folium
import numpy as np  # np mean, np random
import pandas as pd  # read csv, df manipulation
import streamlit as st  # ğŸˆ data web app development
from streamlit_autorefresh import st_autorefresh

import requests
import json

st.set_page_config(
    page_title="Real-Time Data",
    page_icon="âœ…",
    layout="wide",
)

st.title("ì˜ì—…ì  ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ")
st_autorefresh(interval=20 * 1000, key="dataframerefresh")

# ì„œìš¸ í–‰ì •êµ¬ì—­ json rawíŒŒì¼(githubcontent)
r = requests.get('https://raw.githubusercontent.com/southkorea/seoul-maps/master/kostat/2013/json/seoul_municipalities_geo_simple.json')
c = r.content
seoul_geo = json.loads(c)

# m = folium.Map(
#     location=[37.559819, 126.963895],
#     zoom_start=11, 
#     tiles='cartodbpositron'
# )

# folium.GeoJson(
#     seoul_geo,
#     name='ì§€ì—­êµ¬'
# ).add_to(m)


conn = msql.connect(host='52.36.29.255', database='pets', user='bigdata',
    password='1111')

cursor = conn.cursor()

sql2 = "SELECT * from streamlit_day"
cursor.execute(sql2)

result2 = cursor.fetchall()

df2=pd.DataFrame(result2)
job_filter = st.selectbox("ì§€ì—­ì„ ì„ íƒí•˜ì„¸ìš”", pd.unique(df2[0]))
df2 = df2[df2[0] == job_filter]
#print(df2)


sql3 = "SELECT * from streamlit_upper"
cursor.execute(sql3)

result3 = cursor.fetchall()

df3=pd.DataFrame(result3)
df3 = df3[df3[0] == job_filter]
print(df3)


col1, col2, col3 = st.columns(3)
col1.metric("ê°•ë‚¨êµ¬ ì˜ì—…ì  ìˆ˜", str(df3.iat[0,1]), "4ê°œ")
col2.metric("ì´ ì¸êµ¬ ìˆ˜", str(df3.iat[0,2]), "-1,000ëª…")
col3.metric("ì¢…í•©ì ìˆ˜", "86ì ", "5")

from streamlit_folium import st_folium
import folium

## ì§€ë„--------------------------------------------------
m = folium.Map(
    location=[37.559819, 126.963895],
    zoom_start=11, 
    tiles='cartodbpositron'
)

folium.GeoJson(
    seoul_geo,
    name='ì§€ì—­êµ¬'
).add_to(m)

if job_filter=='ê°•ë‚¨êµ¬':
    folium.Marker(
      location=[37.49108397,127.05536209],
      #popup="<a href=http://35.88.197.65:8088/superset/dashboard/p/mdZK1LrRA2w/>Place Guillaume II</a>",
      popup='<a href="http://35.88.197.65:8088/superset/dashboard/p/mdZK1LrRA2w/" target="_blank">ê°•ë‚¨êµ¬</a>',
      icon=folium.Icon(color='red',icon='star')
    ).add_to(m)
    
eliif job_filter=='ì˜ë“±í¬êµ¬':
    folium.Marker(
      location=[37.51527262,126.90702140],
      #popup="<a href=http://35.88.197.65:8088/superset/dashboard/p/mdZK1LrRA2w/>Place Guillaume II</a>",
      popup='<a href="http://35.88.197.65:8088/superset/dashboard/p/mdZK1LrRA2w/" target="_blank">ì˜ë“±í¬êµ¬</a>',
      icon=folium.Icon(color='red',icon='star')
    ).add_to(m)
eliif job_filter=='ê´€ì•…êµ¬':
    folium.Marker(
      location=[37.471077623795,126.93920205178],
      #popup="<a href=http://35.88.197.65:8088/superset/dashboard/p/mdZK1LrRA2w/>Place Guillaume II</a>",
      popup='<a href="http://35.88.197.65:8088/superset/dashboard/p/mdZK1LrRA2w/" target="_blank">ê´€ì•…êµ¬</a>',
      icon=folium.Icon(color='red',icon='star')
    ).add_to(m)

import pandas as pd

folium_data = [
            ['ê°•ë‚¨êµ¬', 33],
            ['ê°•ë™êµ¬', 44],
            ['ê°•ë¶êµ¬', 43],
            ['ê°•ì„œêµ¬', 35],
            ['ê´€ì•…êµ¬', 54],
            ['ê´‘ì§„êµ¬', 34],
            ['êµ¬ë¡œêµ¬',34],
            ['ë™ì‘êµ¬', 34],
            ['ë§ˆí¬êµ¬', 55],
            ['ì„œëŒ€ë¬¸êµ¬', 44],
            ['ë™ëŒ€ë¬¸êµ¬', 33],
            ['ì„œì´ˆêµ¬', 34],
            ['ì„±ë™êµ¬', 35],
            ['ì„±ë¶êµ¬', 45],
            ['ì†¡íŒŒêµ¬', 65],
            ['ìš©ì‚°êµ¬', 44],
            ['ì–‘ì²œêµ¬', 33],
            ['ì˜ë“±í¬êµ¬', 45],
            ['ì€í‰êµ¬', 34],
            ['ì¢…ë¡œêµ¬', 45],
            ['ì¤‘êµ¬', 55],
            ['ì¤‘ë‘êµ¬', 8],
]

folium_data = pd.DataFrame(folium_data,columns=['êµ¬','ìˆ˜'])



#ì›Œë“œí´ë¼ìš°ë“œ---------------
from PIL import Image
image = 'https://superset22.s3.us-west-2.amazonaws.com/%ED%99%94%EB%A9%B4+%EC%BA%A1%EC%B2%98+2022-07-25+191136.png'
image2 = 'https://superset22.s3.us-west-2.amazonaws.com/%ED%99%94%EB%A9%B4+%EC%BA%A1%EC%B2%98+2022-07-25+185153.png'

fig_col1, fig_col2  = st.columns(2)

with fig_col1:
    st_data = st_folium(m, width = 1300)
    #st.image(image, caption='ìš°ë¦¬ì€í–‰ WordCloud',output_format="auto", width=250)

with fig_col2:
    st.image(image2, caption='ì˜ì—…ì  WordCloud',output_format="auto", width=250)


# auto-refresh
#st_data = st_folium(m, width = 1300)


#---------------------------------
import pandas as pd
import altair as alt
sql4 = "SELECT * from streamlit_day_final4"
cursor.execute(sql4)

result4 = cursor.fetchall()

df4=pd.DataFrame(result4)
df4 = df4[df4[0] == job_filter]
a=[]; b=[]; year=[]
for i in range(len(df4)):
    a.append(df4.iat[i,1])

for i in range(len(df4)):
    b.append(df4.iat[i,2])

for i in range(len(df4)):
    year.append(df4.iat[i,6])

print(a)
#print(df4.iat[1,6])
#print(df4.iat[0,1])

df = pd.DataFrame(
    {
        'Duration': [f"{d} ì‹œê°„" for d in year],
        'ê°œì¸ê³ ê°': a,
        'ê¸°ì—…ê³ ê°': b
    },
    columns=['Duration', 'ê°œì¸ê³ ê°', 'ê¸°ì—…ê³ ê°']
)



#st.write(df)



df = df.melt('Duration', var_name='name', value_name='value')
#st.write(df)

chart = alt.Chart(df).mark_line().encode(
  x=alt.X('Duration:N'),
  y=alt.Y('value:Q'),
  color=alt.Color("name:N")
).properties(title="ëŒ€ê¸°í˜„í™©")
st.altair_chart(chart, use_container_width=True)


# sql = "SELECT * from personal_company"
# cursor.execute(sql)

# result = cursor.fetchall()

# df=pd.DataFrame(result)


# st.markdown("### Detailed Data View")
# st.dataframe(df)

# data=[[5, 33, 11],
#  [6, 22, 16],
#  [4, 11, 20],
#  [5, 23, 19],
#  [5, 24, 18],
#  [5, 17, 17],
#  [6, 16, 15]]

# chart_data = pd.DataFrame(
#      data,
#      columns=['ê°•ë‚¨êµ¬', 'ê´€ì•…êµ¬', 'ì˜ë“±í¬êµ¬'])

# st.line_chart(chart_data)
